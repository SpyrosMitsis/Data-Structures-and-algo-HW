import pandas as pd
import matplotlib.pyplot as plt
import numpy as np


data = pd.read_csv('linear_dataset.csv')

plt.scatter(data.x, data.y)



def loss_function(m, b, dataset):
    total_error = 0
    for i in range(dataset):
        x = dataset.iloc[i].x
        y = dataset.iloc[i].y
        total_error += (y - (m * x + b)) ** 2
    total_error / float(len(dataset))


def gradient_descent(m_now, b_now, dataset, L):
    m_gradient = 0
    b_gradient = 0

    n = len(dataset)

    for i in range(n):
        x = dataset.iloc[i].x
        y = dataset.iloc[i].y

        m_gradient += -(2/n) * x * (y - (m_now * x + b_now))
        b_gradient += -(2/n) * (y - (m_now * x + b_now))

    m = m_now - m_gradient * L
    b = b_now - b_gradient * L

    return m, b


m = 0
b = 0
L = 0.001

epochs = 1000

for i in range(epochs):
    m, b = gradient_descent(m, b, data, L) 

print(m, b)



plt.scatter(data.x, data.y, )
plt.plot(list(range(0, 11)), [m * x + b for x in range(0,11)], color="red")


quad = pd.read_csv("quadratic_data.csv")
plt.scatter(quad.x, quad.y)


def quad_gradient_descent(a_now, b_now, c_now, dataset, L):
    a_gradient = 0
    b_gradient = 0
    c_gradient = 0

    n = len(dataset)

    for i in range(n):
        x = dataset.iloc[i].x
        y = dataset.iloc[i].y

        a_gradient += -(2/n) * x ** 2 * (y - (a_now * x**2 + b_now * x + c_now))
        # print("a gradient: {}".format(a_gradient), end=" ")
        b_gradient += -(2/n) * x * (y - (a_now * x**2 + b_now * x + c_now))
        # print("b gradient: {}".format(b_gradient), end=" ")
        c_gradient += -(2/n) * (y - (a_now * x**2 + b_now * x + c_now))
        # print("c gradient: {}".format(c_gradient))

    a = a_now - a_gradient * L
    b = b_now - b_gradient * L
    c = c_now - c_gradient * L

    return a, b, c





a = 0
b = 0
c = 0
L = 0.0001

epochs = 10000

for i in range(epochs):
    a, b, c = quad_gradient_descent(a, b, c, quad, L)

print(a, b, c)



plt.scatter(quad.x, quad.y)
x_range = np.linspace(-10, 10, 100)
quadratic_curve = a * x_range**2 + b * x_range + c
plt.plot(x_range, quadratic_curve, color="red")


log = pd.read_csv("log_curve.csv")
plt.scatter(log.x, log.y)


def log_gradient_descent(a_now, b_now, dataset, L):
    a_gradient = 0
    b_gradient = 0

    n = len(dataset)

    for i in range(n):
        x = dataset.iloc[i].x
        y = dataset.iloc[i].y

        a_gradient += -(2/n) * (y - (a_now + b_now * np.log(x)))
        b_gradient += -(2/n) * np.log(x) * (y - (a_now + b_now * np.log(x)))

    a = a_now - a_gradient * L
    b = b_now - b_gradient * L

    return a, b


a = 0
b = 0
L = 0.001

epochs = 10000

for i in range(epochs):
    a, b = log_gradient_descent(a, b, log, L)

print(a, b)



plt.scatter(log.x, log.y)
A_range = np.linspace(0, 10)
log_curve = a + b * np.log(x_range)
plt.plot(x_range, log_curve, color="red")
